import os
import json
import numpy as np
import argparse
from multiprocessing import Pool, cpu_count
import tqdm

# ================= é…ç½® =================
# å¿…é¡»ä¸ action.py çš„ get_property_list ä¸¥æ ¼ä¸€è‡´
INDEX_GRIPPER = 4
INDEX_JOINT = 8
JOINT_DIM = 14          # å…³èŠ‚ç»´åº¦
TOTAL_OUTPUT_DIM = 32   # æœ€ç»ˆå¯¹é½åˆ° 32 ç»´ï¼ˆå‰ 14 ç»´æœ‰æ•ˆï¼‰

# æ¯ä¸ª episode é‡‡æ ·å¤šå°‘æ¡ç”¨äºåˆ†ä½æ•°ä¼°è®¡ï¼ˆé˜²æ­¢å†…å­˜çˆ†æ‰ï¼‰
STATE_SAMPLES_PER_EP = 2000
ACTION_SAMPLES_PER_EP = 2000


def parse_args():
    parser = argparse.ArgumentParser(description="Fast Parallel Dataset Mean/Std/Quantile Compute")
    parser.add_argument(
        "--root_dir",
        type=str,
        default="/home/v-zhifeng/HPE/v-zhifeng/agibot_beta_split_500/actions_gaussian",
    )
    parser.add_argument("--meta_file", type=str, default="meta_data.json")
    parser.add_argument("--output_json", type=str, default="dataset_stats_mp.json")
    parser.add_argument("--workers", type=int, default=32, help="Number of parallel processes")
    return parser.parse_args()


def load_data_custom(npy_path, dim_list):
    """
    Worker è¿›ç¨‹è¯»å–å•ä¸ªæ–‡ä»¶çš„é€»è¾‘ï¼š
    - ä» action.npy ä¸­æŒ‰ dim_list åˆ‡å‡º Joint æ®µ (INDEX_JOINT)
    - è¿”å› shape: (T, JOINT_DIM)
    """
    try:
        expected_dim = sum(dim_list)
        with open(npy_path, "rb") as f:
            raw_data = np.fromfile(f, dtype=np.float32)

        if raw_data.size % expected_dim != 0:
            return None

        T = raw_data.size // expected_dim
        matrix = raw_data.reshape(T, expected_dim)

        # å¿«é€Ÿåˆ‡ç‰‡æå– Joint æ•°æ®
        current_idx = 0
        for i, dim in enumerate(dim_list):
            if i == INDEX_JOINT:
                return matrix[:, current_idx : current_idx + dim]
            current_idx += dim
        return None
    except Exception:
        return None


def process_episode(args):
    """
    Worker å‡½æ•°ï¼šå¤„ç†å•ä¸ª Episodeï¼Œè¿”å›ç»Ÿè®¡é‡çš„ä¸­é—´ç»“æœ (Sum, SqSum, Count)
    å‚æ•° args æ˜¯ä¸€ä¸ª tuple: (root_dir, ep_key, dim_list)

    è¿”å›ï¼š
      (s_sum, s_sq_sum, s_count,
       a_sum, a_sq_sum, a_count,
       sample_state, sample_action)
    å…¶ä¸­ sample_state / sample_action ç”¨äºåé¢ä¼°è®¡ q01/q99ã€‚
    """
    root_dir, ep_key, dim_list = args
    npy_path = os.path.join(root_dir, ep_key, "action.npy")

    if not os.path.exists(npy_path):
        return None

    # åŠ è½½æ•°æ®
    joints = load_data_custom(npy_path, dim_list)
    if joints is None or joints.shape[1] != JOINT_DIM:
        return None

    joints = joints.astype(np.float64)
    T = joints.shape[0]
    if T < 2:
        return None

    # --- 1. State Stats (Joints Abs) ---
    s_sum = np.sum(joints, axis=0)
    s_sq_sum = np.sum(joints ** 2, axis=0)
    s_count = T

    # --- 2. Action Stats (Joints Delta) ---
    joint_delta = joints[1:] - joints[:-1]
    a_sum = np.sum(joint_delta, axis=0)
    a_sq_sum = np.sum(joint_delta ** 2, axis=0)
    a_count = T - 1

    # --- 3. ä¸ºåˆ†ä½æ•°ä¼°è®¡é‡‡æ · ---
    # state é‡‡æ ·
    if T > STATE_SAMPLES_PER_EP:
        idx_state = np.random.choice(T, STATE_SAMPLES_PER_EP, replace=False)
        sample_state = joints[idx_state]
    else:
        sample_state = joints.copy()

    # action é‡‡æ ·
    Td = joint_delta.shape[0]
    if Td > ACTION_SAMPLES_PER_EP:
        idx_action = np.random.choice(Td, ACTION_SAMPLES_PER_EP, replace=False)
        sample_action = joint_delta[idx_action]
    else:
        sample_action = joint_delta.copy()

    return (s_sum, s_sq_sum, s_count,
            a_sum, a_sq_sum, a_count,
            sample_state, sample_action)


def main():
    args = parse_args()

    # 1. åŠ è½½ Meta Data
    meta_path = os.path.join(args.root_dir, args.meta_file)
    print(f"ğŸ“– Loading meta data from {meta_path}...")
    with open(meta_path, "r") as f:
        meta_data = json.load(f)

    episodes = list(meta_data.keys())
    total_episodes = len(episodes)

    # 2. å‡†å¤‡ä»»åŠ¡å‚æ•°åˆ—è¡¨
    tasks = []
    for ep_key in episodes:
        tasks.append((args.root_dir, ep_key, meta_data[ep_key]["dim_list"]))

    # 3. ç¡®å®šè¿›ç¨‹æ•°
    num_workers = args.workers if args.workers > 0 else max(1, cpu_count() - 2)
    print(f"ğŸš€ Starting multiprocessing with {num_workers} workers for {total_episodes} episodes...")

    # 4. å…¨å±€ç´¯åŠ å™¨ (float64)
    total_state_sum = np.zeros(JOINT_DIM, dtype=np.float64)
    total_state_sq_sum = np.zeros(JOINT_DIM, dtype=np.float64)
    total_state_count = 0

    total_action_sum = np.zeros(JOINT_DIM, dtype=np.float64)
    total_action_sq_sum = np.zeros(JOINT_DIM, dtype=np.float64)
    total_action_count = 0

    valid_files = 0

    # ç”¨äºåˆ†ä½æ•°ä¼°è®¡çš„å…¨å±€é‡‡æ ·ç¼“å­˜
    all_state_samples = []
    all_action_samples = []

    # 5. å¹¶è¡Œæ‰§è¡Œ
    with Pool(processes=num_workers) as pool:
        results = list(
            tqdm.tqdm(
                pool.imap_unordered(process_episode, tasks, chunksize=50),
                total=total_episodes,
            )
        )

    print("ğŸ“Š Aggregating results...")

    # 6. æ±‡æ€»ç»“æœ
    for res in results:
        if res is None:
            continue

        (
            s_sum,
            s_sq_sum,
            s_cnt,
            a_sum,
            a_sq_sum,
            a_cnt,
            sample_state,
            sample_action,
        ) = res

        total_state_sum += s_sum
        total_state_sq_sum += s_sq_sum
        total_state_count += s_cnt

        total_action_sum += a_sum
        total_action_sq_sum += a_sq_sum
        total_action_count += a_cnt

        all_state_samples.append(sample_state)
        all_action_samples.append(sample_action)

        valid_files += 1

    print(f"âœ… Processed {valid_files} valid files.")

    if total_state_count == 0 or total_action_count == 0:
        print("âŒ No valid data found.")
        return

    # 7. è®¡ç®— Mean/Std
    state_mean = total_state_sum / total_state_count
    state_std = np.sqrt((total_state_sq_sum / total_state_count) - (state_mean ** 2) + 1e-8)

    action_mean = total_action_sum / total_action_count
    action_std = np.sqrt((total_action_sq_sum / total_action_count) - (action_mean ** 2) + 1e-8)

    # 8. è®¡ç®— q01 / q99ï¼ˆåŸºäºé‡‡æ ·ï¼‰
    print("ğŸ“Œ Computing percentiles (q01 / q99) from samples...")

    all_state_samples_np = np.vstack(all_state_samples)  # (N_state, JOINT_DIM)
    all_action_samples_np = np.vstack(all_action_samples)  # (N_action, JOINT_DIM)

    state_q01 = np.percentile(all_state_samples_np, 1, axis=0)
    state_q99 = np.percentile(all_state_samples_np, 99, axis=0)

    action_q01 = np.percentile(all_action_samples_np, 1, axis=0)
    action_q99 = np.percentile(all_action_samples_np, 99, axis=0)

    # 9. æ ¼å¼åŒ–è¾“å‡º (Padding åˆ° 32 ç»´)
    def format_output(mean_arr, std_arr, q01_arr=None, q99_arr=None):
        final_mean = np.zeros(TOTAL_OUTPUT_DIM, dtype=np.float32)
        final_std = np.ones(TOTAL_OUTPUT_DIM, dtype=np.float32)

        final_mean[:JOINT_DIM] = mean_arr.astype(np.float32)
        final_std[:JOINT_DIM] = std_arr.astype(np.float32)

        out = {
            "mean": final_mean.tolist(),
            "std": final_std.tolist(),
        }

        if q01_arr is not None and q99_arr is not None:
            final_q01 = np.zeros(TOTAL_OUTPUT_DIM, dtype=np.float32)
            final_q99 = np.zeros(TOTAL_OUTPUT_DIM, dtype=np.float32)
            final_q01[:JOINT_DIM] = q01_arr.astype(np.float32)
            final_q99[:JOINT_DIM] = q99_arr.astype(np.float32)
            out["q01"] = final_q01.tolist()
            out["q99"] = final_q99.tolist()

        return out

    state_stats = format_output(state_mean, state_std, state_q01, state_q99)
    action_stats = format_output(action_mean, action_std, action_q01, action_q99)

    stats_dict = {
        "norm_stats": {
            "state": state_stats,
            "actions": action_stats,
        }
    }

    save_path = os.path.join(args.root_dir, args.output_json)
    with open(save_path, "w") as f:
        json.dump(stats_dict, f, indent=2)

    print("\n" + "=" * 50)
    print(f"âœ… Fast Stats saved to: {save_path}")
    print(f"   Workers used: {num_workers}")
    print(f"   State Joint Mean (First 5): {state_mean[:5]}")
    print(f"   State Joint q01  (First 5): {state_q01[:5]}")
    print(f"   State Joint q99  (First 5): {state_q99[:5]}")
    print("=" * 50)


if __name__ == "__main__":
    main()
